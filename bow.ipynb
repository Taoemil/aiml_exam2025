{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# adjust path as needed\n",
    "train_df = pd.read_csv(\"data/kaggle/train.csv\")\n",
    "test_df  = pd.read_csv(\"data/kaggle/test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(train_df.head())\n",
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "print(train_df[label_cols].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)           # strip HTML tags\n",
    "    text = re.sub(r\"https?://\\S+\", \" \", text)    # strip URLs\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)        # keep only letters & spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "train_df['comment_text'] = train_df['comment_text'].apply(clean_text)\n",
    "test_df['comment_text']  = test_df['comment_text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6170b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_df['comment_text'],\n",
    "    train_df[label_cols],\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee116dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=10_000, \n",
    "    stop_words='english', \n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_val_bow   = vectorizer.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# initialize\n",
    "base_clf = LogisticRegression(C=1.0, max_iter=200)\n",
    "model = OneVsRestClassifier(base_clf, n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train_bow, y_train)\n",
    "\n",
    "# predict probabilities on validation\n",
    "y_val_pred = model.predict_proba(X_val_bow)\n",
    "\n",
    "# compute AUC for each label\n",
    "for i, label in enumerate(label_cols):\n",
    "    auc = roc_auc_score(y_val[label], y_val_pred[:, i])\n",
    "    print(f\"{label} AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee900f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# initialize\n",
    "base_clf = LogisticRegression(C=1.0, max_iter=200)\n",
    "model = OneVsRestClassifier(base_clf, n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train_bow, y_train)\n",
    "\n",
    "# predict probabilities on validation\n",
    "y_val_pred = model.predict_proba(X_val_bow)\n",
    "\n",
    "# compute AUC for each label\n",
    "for i, label in enumerate(label_cols):\n",
    "    auc = roc_auc_score(y_val[label], y_val_pred[:, i])\n",
    "    print(f\"{label} AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(), n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'vect__max_features': [5_000, 10_000, 20_000],\n",
    "    'vect__ngram_range': [(1,1), (1,2)],\n",
    "    'clf__estimator__C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23088bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# retrain on full data\n",
    "full_vect = CountVectorizer(max_features=10_000, stop_words='english', ngram_range=(1,2))\n",
    "X_full = full_vect.fit_transform(train_df['comment_text'])\n",
    "\n",
    "final_clf = OneVsRestClassifier(LogisticRegression(C=1.0, max_iter=200), n_jobs=-1)\n",
    "final_clf.fit(X_full, train_df[label_cols])\n",
    "\n",
    "# predict on test\n",
    "X_test = full_vect.transform(test_df['comment_text'])\n",
    "probs = final_clf.predict_proba(X_test)\n",
    "\n",
    "sub = pd.DataFrame(probs, columns=label_cols)\n",
    "sub.insert(0, 'id', test_df['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89b56ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions:\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  1.000000      0.029503  1.000000  0.039739  0.999935   \n",
      "1  0000247867823ef7  0.009600      0.005285  0.002576  0.001493  0.004915   \n",
      "2  00013b17ad220c46  0.056865      0.005284  0.022372  0.001323  0.032402   \n",
      "3  00017563c3f7919a  0.000966      0.000185  0.000952  0.000056  0.000715   \n",
      "4  00017695ad8997eb  0.023909      0.007190  0.010391  0.003560  0.035509   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.632566  \n",
      "1       0.002123  \n",
      "2       0.011014  \n",
      "3       0.000020  \n",
      "4       0.008936   \n",
      "\n",
      "Summary statistics of predicted probabilities:\n",
      "                  count      mean       std           min       25%       50%  \\\n",
      "toxic          153164.0  0.197519  0.333026  8.125400e-75  0.000996  0.021087   \n",
      "severe_toxic   153164.0  0.017504  0.082349  0.000000e+00  0.000056  0.001564   \n",
      "obscene        153164.0  0.116715  0.270034  0.000000e+00  0.000658  0.007829   \n",
      "threat         153164.0  0.006373  0.059078  0.000000e+00  0.000013  0.000340   \n",
      "insult         153164.0  0.090207  0.215440  0.000000e+00  0.000617  0.008637   \n",
      "identity_hate  153164.0  0.018264  0.093833  0.000000e+00  0.000025  0.000949   \n",
      "\n",
      "                    75%  max  \n",
      "toxic          0.176102  1.0  \n",
      "severe_toxic   0.009664  1.0  \n",
      "obscene        0.032801  1.0  \n",
      "threat         0.001877  1.0  \n",
      "insult         0.038824  1.0  \n",
      "identity_hate  0.006981  1.0   \n",
      "\n",
      "ROC AUC per label:\n",
      "  toxic          : 0.9366\n",
      "  severe_toxic   : 0.9482\n",
      "  obscene        : 0.9574\n",
      "  threat         : 0.9620\n",
      "  insult         : 0.9458\n",
      "  identity_hate  : 0.9560\n",
      "\n",
      "Classification Report (threshold=0.5):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.58      0.70      0.63      6090\n",
      " severe_toxic       0.40      0.40      0.40       367\n",
      "      obscene       0.66      0.64      0.65      3691\n",
      "       threat       0.24      0.28      0.26       211\n",
      "       insult       0.66      0.48      0.56      3427\n",
      "identity_hate       0.46      0.34      0.39       712\n",
      "\n",
      "    micro avg       0.60      0.60      0.60     14498\n",
      "    macro avg       0.50      0.47      0.48     14498\n",
      " weighted avg       0.60      0.60      0.60     14498\n",
      "  samples avg       0.06      0.06      0.06     14498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Quick look at your “submission” table ---\n",
    "print(\"First 5 predictions:\")\n",
    "print(sub.head(), \"\\n\")\n",
    "\n",
    "print(\"Summary statistics of predicted probabilities:\")\n",
    "print(sub.describe().T, \"\\n\")\n",
    "\n",
    "# --- 2) If you want to evaluate on the scored subset: ---\n",
    "# (make sure you have loaded test_labels.csv already)\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "test_labels = pd.read_csv(\"data/kaggle/test_labels.csv\")      # adjust path\n",
    "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "# pick only those rows where test_labels != -1 for all labels\n",
    "mask = (test_labels[label_cols] != -1).all(axis=1)\n",
    "scored = test_labels[mask].set_index('id')\n",
    "\n",
    "# align predictions to the scored IDs\n",
    "preds = sub.set_index('id').loc[scored.index, label_cols]\n",
    "\n",
    "# compute per-label ROC AUC\n",
    "print(\"ROC AUC per label:\")\n",
    "for col in label_cols:\n",
    "    auc = roc_auc_score(scored[col], preds[col])\n",
    "    print(f\"  {col:15s}: {auc:.4f}\")\n",
    "\n",
    "# classification report @ 0.5 threshold\n",
    "binary_preds = (preds >= 0.5).astype(int)\n",
    "print(\"\\nClassification Report (threshold=0.5):\")\n",
    "print(classification_report(scored, binary_preds, target_names=label_cols))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-project)",
   "language": "python",
   "name": "exam_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
