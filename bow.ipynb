{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae7f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# paths to data\n",
    "train_df = pd.read_csv(\"data/kaggle/train.csv\")\n",
    "test_df  = pd.read_csv(\"data/kaggle/test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(train_df.head())\n",
    "print(train_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "print(train_df[label_cols].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4831e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)           # strip HTML tags\n",
    "    text = re.sub(r\"https?://\\S+\", \" \", text)    # strip URLs\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)        # keep only letters & spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "train_df['comment_text'] = train_df['comment_text'].apply(clean_text)\n",
    "test_df['comment_text']  = test_df['comment_text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6170b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_df['comment_text'],\n",
    "    train_df[label_cols],\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee116dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=10_000, \n",
    "    stop_words='english', \n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_val_bow   = vectorizer.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# initialize\n",
    "base_clf = LogisticRegression(C=1.0, max_iter=200)\n",
    "model = OneVsRestClassifier(base_clf, n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train_bow, y_train)\n",
    "\n",
    "# predict probabilities on validation\n",
    "y_val_pred = model.predict_proba(X_val_bow)\n",
    "\n",
    "# compute AUC for each label\n",
    "for i, label in enumerate(label_cols):\n",
    "    auc = roc_auc_score(y_val[label], y_val_pred[:, i])\n",
    "    print(f\"{label} AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee900f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# initialize\n",
    "base_clf = LogisticRegression(C=1.0, max_iter=200)\n",
    "model = OneVsRestClassifier(base_clf, n_jobs=-1)\n",
    "\n",
    "# fit\n",
    "model.fit(X_train_bow, y_train)\n",
    "\n",
    "# predict probabilities on validation\n",
    "y_val_pred = model.predict_proba(X_val_bow)\n",
    "\n",
    "# compute AUC for each label\n",
    "for i, label in enumerate(label_cols):\n",
    "    auc = roc_auc_score(y_val[label], y_val_pred[:, i])\n",
    "    print(f\"{label} AUC: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(), n_jobs=-1))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'vect__max_features': [5_000, 10_000, 20_000],\n",
    "    'vect__ngram_range': [(1,1), (1,2)],\n",
    "    'clf__estimator__C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23088bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain on full data\n",
    "full_vect = CountVectorizer(max_features=10_000, stop_words='english', ngram_range=(1,2))\n",
    "X_full = full_vect.fit_transform(train_df['comment_text'])\n",
    "\n",
    "final_clf = OneVsRestClassifier(LogisticRegression(C=1.0, max_iter=200), n_jobs=-1)\n",
    "final_clf.fit(X_full, train_df[label_cols])\n",
    "\n",
    "# predict on test\n",
    "X_test = full_vect.transform(test_df['comment_text'])\n",
    "probs = final_clf.predict_proba(X_test)\n",
    "\n",
    "sub = pd.DataFrame(probs, columns=label_cols)\n",
    "sub.insert(0, 'id', test_df['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b56ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"First 5 predictions:\")\n",
    "print(sub.head(), \"\\n\")\n",
    "\n",
    "print(\"Summary statistics of predicted probabilities:\")\n",
    "print(sub.describe().T, \"\\n\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "test_labels = pd.read_csv(\"data/kaggle/test_labels.csv\")      # adjust path\n",
    "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "\n",
    "mask = (test_labels[label_cols] != -1).all(axis=1)\n",
    "scored = test_labels[mask].set_index('id')\n",
    "\n",
    "# align predictions to the scored IDs\n",
    "preds = sub.set_index('id').loc[scored.index, label_cols]\n",
    "\n",
    "# compute per-label ROC AUC\n",
    "print(\"ROC AUC per label:\")\n",
    "for col in label_cols:\n",
    "    auc = roc_auc_score(scored[col], preds[col])\n",
    "    print(f\"  {col:15s}: {auc:.4f}\")\n",
    "\n",
    "# classification report @ 0.5 threshold\n",
    "binary_preds = (preds >= 0.5).astype(int)\n",
    "print(\"\\nClassification Report (threshold=0.5):\")\n",
    "print(classification_report(scored, binary_preds, target_names=label_cols))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-project)",
   "language": "python",
   "name": "exam_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
