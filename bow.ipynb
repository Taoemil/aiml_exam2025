{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1df3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e8637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "train_df = pd.read_csv('data/kaggle/train.csv')\n",
    "test_df = pd.read_csv('data/kaggle/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ea50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and multi-label targets\n",
    "X = train_df['comment_text']\n",
    "y = train_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b227c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split into train/validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "578ee124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define baseline pipelines for each model\n",
    "pipelines = {\n",
    "    'lr_cv_baseline': Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(max_iter=1000, n_jobs=-1)))\n",
    "    ]),\n",
    "    'lr_tv_baseline': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression(max_iter=1000, n_jobs=-1)))\n",
    "    ]),\n",
    "    'rf_cv_baseline': Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('clf', OneVsRestClassifier(RandomForestClassifier(n_jobs=-1)))\n",
    "    ]),\n",
    "    'rf_tv_baseline': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('clf', OneVsRestClassifier(RandomForestClassifier(n_jobs=-1)))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba340e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate each baseline model\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"\\n=== {name} - Training ===\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(f\"=== {name} - Evaluation ===\")\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    print(classification_report(y_val, y_pred, target_names=y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c6162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning setup, lr_cv & lr_tv\n",
    "tuned_pipelines = {\n",
    "    'lr_cv_tuned': pipelines['lr_cv_baseline'],\n",
    "    'lr_tv_tuned': pipelines['lr_tv_baseline'],\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'lr_cv_tuned': {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'vect__max_df': [0.75, 0.9],\n",
    "        'vect__min_df': [1, 2],\n",
    "        'clf__estimator__C': [0.1, 1, 10]\n",
    "    },\n",
    "    'lr_tv_tuned': {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "        'vect__max_df': [0.75, 0.9],\n",
    "        'vect__min_df': [1, 2],\n",
    "        'clf__estimator__C': [0.1, 1, 10]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning setup, rf_cv & rf_tv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4857a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run GridSearchCV for each lr_tv and lr_cv\n",
    "for name, pipeline in tuned_pipelines.items():\n",
    "    print(f\"\\n--- Hyperparameter tuning: {name} ---\")\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grids[name],\n",
    "        scoring='f1_macro',\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(f\"Best params for {name}:\", gs.best_params_)\n",
    "    y_pred = gs.predict(X_val)\n",
    "    print(classification_report(y_val, y_pred, target_names=y.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "506ba491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze best vectorizer settings\n",
    "best_vect_params = {\n",
    "    'ngram_range': (1, 2),\n",
    "    'max_df': 0.9,\n",
    "    'min_df': 1\n",
    "}\n",
    "\n",
    "# Define simplified RF pipelines (single-threaded inner estimator) to reduce runtime\n",
    "rf_cv_tuned = Pipeline([\n",
    "    ('vect', CountVectorizer(**best_vect_params)),\n",
    "    ('clf', OneVsRestClassifier(\n",
    "        RandomForestClassifier(random_state=42, n_jobs=1)\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_tv_tuned = Pipeline([\n",
    "    ('vect', TfidfVectorizer(**best_vect_params)),\n",
    "    ('clf', OneVsRestClassifier(\n",
    "        RandomForestClassifier(random_state=42, n_jobs=1)\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Slimmed-down RF hyperparameter grid\n",
    "param_grid_rf = {\n",
    "    'clf__estimator__n_estimators':      [100, 200],\n",
    "    'clf__estimator__min_samples_split': [2,   5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "568fef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hyperparameter tuning: rf_cv_tuned (30% subsample) ===\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100; total time= 5.3min\n",
      "[CV] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100; total time= 5.6min\n",
      "[CV] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100; total time= 7.5min\n",
      "[CV] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100; total time= 7.8min\n",
      "[CV] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=200; total time= 9.1min\n",
      "[CV] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=200; total time= 9.4min\n",
      "[CV] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200; total time=11.1min\n",
      "[CV] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200; total time=11.3min\n",
      "Best params for rf_cv_tuned: {'clf__estimator__min_samples_split': 2, 'clf__estimator__n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.98      0.30      0.46      3056\n",
      " severe_toxic       0.57      0.02      0.05       321\n",
      "      obscene       0.96      0.37      0.54      1715\n",
      "       threat       0.00      0.00      0.00        74\n",
      "       insult       0.90      0.22      0.36      1614\n",
      "identity_hate       0.60      0.01      0.02       294\n",
      "\n",
      "    micro avg       0.95      0.27      0.42      7074\n",
      "    macro avg       0.67      0.16      0.24      7074\n",
      " weighted avg       0.91      0.27      0.41      7074\n",
      "  samples avg       0.03      0.02      0.02      7074\n",
      "\n",
      "--- Evaluation for rf_cv_tuned on validation set ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.98      0.30      0.46      3056\n",
      " severe_toxic       0.57      0.02      0.05       321\n",
      "      obscene       0.96      0.37      0.54      1715\n",
      "       threat       0.00      0.00      0.00        74\n",
      "       insult       0.90      0.22      0.36      1614\n",
      "identity_hate       0.60      0.01      0.02       294\n",
      "\n",
      "    micro avg       0.95      0.27      0.42      7074\n",
      "    macro avg       0.67      0.16      0.24      7074\n",
      " weighted avg       0.91      0.27      0.41      7074\n",
      "  samples avg       0.03      0.02      0.02      7074\n",
      "\n",
      "\n",
      "=== Hyperparameter tuning: rf_tv_tuned (30% subsample) ===\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100; total time= 4.5min\n",
      "[CV] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=100; total time= 4.7min\n",
      "[CV] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100; total time= 6.1min\n",
      "[CV] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100; total time= 6.3min\n",
      "[CV] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=200; total time= 7.6min\n",
      "[CV] END clf__estimator__min_samples_split=5, clf__estimator__n_estimators=200; total time= 7.9min\n",
      "[CV] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200; total time= 9.3min\n",
      "[CV] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=200; total time= 9.5min\n",
      "Best params for rf_tv_tuned: {'clf__estimator__min_samples_split': 2, 'clf__estimator__n_estimators': 200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.97      0.31      0.47      3056\n",
      " severe_toxic       0.50      0.02      0.04       321\n",
      "      obscene       0.96      0.38      0.54      1715\n",
      "       threat       0.00      0.00      0.00        74\n",
      "       insult       0.90      0.24      0.37      1614\n",
      "identity_hate       0.67      0.01      0.01       294\n",
      "\n",
      "    micro avg       0.95      0.28      0.43      7074\n",
      "    macro avg       0.67      0.16      0.24      7074\n",
      " weighted avg       0.91      0.28      0.42      7074\n",
      "  samples avg       0.03      0.02      0.02      7074\n",
      "\n",
      "--- Evaluation for rf_tv_tuned on validation set ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.97      0.31      0.47      3056\n",
      " severe_toxic       0.50      0.02      0.04       321\n",
      "      obscene       0.96      0.38      0.54      1715\n",
      "       threat       0.00      0.00      0.00        74\n",
      "       insult       0.90      0.24      0.37      1614\n",
      "identity_hate       0.67      0.01      0.01       294\n",
      "\n",
      "    micro avg       0.95      0.28      0.43      7074\n",
      "    macro avg       0.67      0.16      0.24      7074\n",
      " weighted avg       0.91      0.28      0.42      7074\n",
      "  samples avg       0.03      0.02      0.02      7074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/emil/Desktop/CM IT /1 år/2 semester/aiml25/exam_code/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "#  Run GridSearchCV for rf_cv and rf_tv\n",
    "# reduce runtime by using smaller amount of training data\n",
    "X_train_sub, _, y_train_sub, _ = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    train_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "#  run  RF GridSearchCV on X_train_sub / y_train_sub\n",
    "for name, pipeline in [('rf_cv_tuned', rf_cv_tuned), ('rf_tv_tuned', rf_tv_tuned)]:\n",
    "    print(f\"\\n=== Hyperparameter tuning: {name} (30% subsample) ===\")\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid_rf,\n",
    "        scoring='f1_macro',\n",
    "        cv=2,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    gs.fit(X_train_sub, y_train_sub)\n",
    "    print(f\"Best params for {name}:\", gs.best_params_)\n",
    "    y_pred = gs.predict(X_val)\n",
    "    print(classification_report(y_val, y_pred, target_names=y.columns))\n",
    "    \n",
    "    # Evaluate on the **full** validation set\n",
    "    y_pred = gs.predict(X_val)\n",
    "    print(f\"--- Evaluation for {name} on validation set ---\")\n",
    "    print(classification_report(y_val, y_pred, target_names=y.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d435b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-project)",
   "language": "python",
   "name": "exam_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
