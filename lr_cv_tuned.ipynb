{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236ce035",
   "metadata": {},
   "source": [
    "Run best model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6dcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full training data\n",
    "train_df = pd.read_csv('data/kaggle/train.csv')\n",
    "\n",
    "\n",
    "X_full = train_df['comment_text']\n",
    "y_full = train_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43507933",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and multi-label targets\n",
    "X = train_df['comment_text']\n",
    "y = train_df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06500238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Split 80% train / 20% eval\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    X_full,\n",
    "    y_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.9, min_df=1)),\n",
    "    ('clf', OneVsRestClassifier(\n",
    "        LogisticRegression(C=1.0, max_iter=1000)\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e5f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e168d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the 20% hold-out split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = final_pipeline.predict(X_eval)\n",
    "print(\"=== Final Model Evaluation on 20% Hold-Out Set ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_eval, y_pred):.3f}\")\n",
    "print(classification_report(\n",
    "    y_eval,\n",
    "    y_pred,\n",
    "    target_names=y_full.columns\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ae863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "model_path = 'lr_cv_tuned_.joblib'\n",
    "joblib.dump(final_pipeline, model_path)\n",
    "print(f\"\\nModel trained on 80% of data and saved to '{model_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d504ebc",
   "metadata": {},
   "source": [
    "TEST MODEL ON DATA SCRAPED FROM REDDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2192dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "MODEL_PATH = Path(\"lr_cv_tuned_.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdcdb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from reddit\n",
    "DATA_DIR = Path(\"data/reddit\")  # or wherever you put them\n",
    "files = [\n",
    "    DATA_DIR / \"r_conservative.csv\",\n",
    "    DATA_DIR / \"r_democrats.csv\",\n",
    "    DATA_DIR / \"r_europe.csv\",\n",
    "    DATA_DIR / \"r_gunners.csv\",\n",
    "    DATA_DIR / \"r_liverpoolfc.csv\",\n",
    "    DATA_DIR / \"r_politics.csv\",\n",
    "    DATA_DIR / \"r_worldnews.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & concatenate\n",
    "df_list = [pd.read_csv(f) for f in files]\n",
    "df_all  = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aaa6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline\n",
    "model = joblib.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f9fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100-comment random sample\n",
    "df_sample = df_all.sample(n=100, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 100 comment sample\n",
    "\n",
    "label_cols = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "preds = model.predict(df_sample[\"body\"])    # shape (n_samples, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all comments\n",
    "label_cols = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
    "preds = model.predict(df_all[\"body\"])    # shape (n_samples, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d5d04",
   "metadata": {},
   "source": [
    "FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d0069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Reddit-based importance for 'toxic' ===\n",
      "Top 20 →\n",
      "              you : +1701.68\n",
      "             shit : +891.04\n",
      "             fuck : +862.03\n",
      "          fucking : +807.31\n",
      "               is : +684.19\n",
      "               he : +634.37\n",
      "              are : +430.08\n",
      "           stupid : +389.55\n",
      "             hate : +270.75\n",
      "              get : +264.57\n",
      "               go : +252.46\n",
      "           in the : +242.86\n",
      "             your : +230.57\n",
      "             like : +217.96\n",
      "              off : +207.50\n",
      "             want : +181.37\n",
      "            idiot : +150.55\n",
      "              all : +149.38\n",
      "              ass : +141.96\n",
      "               up : +135.75\n",
      "\n",
      "Bottom 20 →\n",
      "              the : -2087.79\n",
      "               to : -1488.91\n",
      "               in : -1037.62\n",
      "               it : -545.29\n",
      "              for : -541.98\n",
      "              but : -483.31\n",
      "              and : -455.44\n",
      "               at : -400.41\n",
      "               of : -388.54\n",
      "              not : -339.13\n",
      "               we : -272.45\n",
      "              can : -246.36\n",
      "            there : -239.78\n",
      "              has : -230.00\n",
      "           please : -228.52\n",
      "           if you : -226.00\n",
      "               as : -221.19\n",
      "               or : -219.28\n",
      "            about : -205.42\n",
      "             from : -198.81\n",
      "\n",
      "=== Reddit-based importance for 'severe_toxic' ===\n",
      "Top 20 →\n",
      "              you : +648.29\n",
      "             fuck : +248.19\n",
      "          fucking : +224.13\n",
      "              him : +176.48\n",
      "             shit : +160.28\n",
      "             will : +159.40\n",
      "           of the : +143.61\n",
      "               us : +140.33\n",
      "         they are : +130.79\n",
      "              she : +119.66\n",
      "              own : +112.70\n",
      "              big : +108.19\n",
      "            to be : +98.71\n",
      "           it was : +98.22\n",
      "           people : +97.60\n",
      "               my : +95.68\n",
      "              had : +89.09\n",
      "             your : +86.55\n",
      "              off : +86.39\n",
      "         that the : +85.79\n",
      "\n",
      "Bottom 20 →\n",
      "              the : -3338.18\n",
      "               it : -1513.70\n",
      "              for : -1387.33\n",
      "               is : -1386.12\n",
      "             that : -1274.01\n",
      "              and : -1262.95\n",
      "               to : -968.89\n",
      "              not : -765.51\n",
      "             with : -733.21\n",
      "               in : -713.19\n",
      "               he : -659.16\n",
      "              was : -657.95\n",
      "               as : -634.83\n",
      "               of : -616.16\n",
      "              but : -592.39\n",
      "               on : -580.43\n",
      "               be : -484.72\n",
      "             this : -454.34\n",
      "              has : -411.17\n",
      "             more : -368.72\n",
      "\n",
      "=== Reddit-based importance for 'obscene' ===\n",
      "Top 20 →\n",
      "              you : +1059.33\n",
      "             fuck : +903.38\n",
      "          fucking : +841.94\n",
      "             shit : +703.01\n",
      "            their : +230.36\n",
      "           stupid : +199.73\n",
      "              off : +185.40\n",
      "               go : +184.25\n",
      "              ass : +152.80\n",
      "             want : +151.60\n",
      "              him : +146.85\n",
      "              are : +143.04\n",
      "           in the : +142.46\n",
      "            being : +141.67\n",
      "         bullshit : +139.34\n",
      "             your : +135.97\n",
      "             they : +130.03\n",
      "              out : +115.25\n",
      "              get : +110.92\n",
      "         with the : +100.96\n",
      "\n",
      "Bottom 20 →\n",
      "              the : -1986.78\n",
      "               to : -993.09\n",
      "               of : -777.75\n",
      "               in : -723.50\n",
      "              not : -514.61\n",
      "              and : -473.79\n",
      "              for : -467.04\n",
      "               if : -387.76\n",
      "             with : -380.73\n",
      "              but : -339.34\n",
      "             from : -338.92\n",
      "             have : -337.56\n",
      "              was : -272.88\n",
      "               as : -240.32\n",
      "               we : -231.11\n",
      "             just : -226.59\n",
      "            could : -209.67\n",
      "            about : -201.29\n",
      "             more : -192.02\n",
      "              war : -190.36\n",
      "\n",
      "=== Reddit-based importance for 'threat' ===\n",
      "Top 20 →\n",
      "             will : +1068.87\n",
      "              you : +884.91\n",
      "              and : +811.27\n",
      "               if : +444.55\n",
      "               ll : +328.69\n",
      "               up : +312.70\n",
      "            going : +301.58\n",
      "             over : +253.42\n",
      "              him : +242.28\n",
      "         going to : +239.43\n",
      "               in : +236.71\n",
      "              our : +231.22\n",
      "               or : +219.83\n",
      "              all : +216.98\n",
      "              who : +205.50\n",
      "              out : +189.44\n",
      "           should : +188.29\n",
      "            right : +182.01\n",
      "            to be : +170.28\n",
      "            death : +153.04\n",
      "\n",
      "Bottom 20 →\n",
      "              the : -4678.56\n",
      "               of : -1994.42\n",
      "               it : -1499.58\n",
      "               is : -1471.71\n",
      "             have : -1240.77\n",
      "               to : -989.25\n",
      "              not : -963.28\n",
      "              are : -924.71\n",
      "             this : -867.29\n",
      "             they : -845.50\n",
      "             that : -753.85\n",
      "              for : -720.83\n",
      "              but : -617.60\n",
      "             just : -538.57\n",
      "              was : -449.05\n",
      "             what : -442.08\n",
      "               so : -441.92\n",
      "               us : -407.81\n",
      "           of the : -384.62\n",
      "              has : -360.65\n",
      "\n",
      "=== Reddit-based importance for 'insult' ===\n",
      "Top 20 →\n",
      "              you : +1594.34\n",
      "               he : +428.47\n",
      "             fuck : +324.33\n",
      "          fucking : +323.35\n",
      "              him : +281.97\n",
      "           stupid : +260.46\n",
      "               is : +258.34\n",
      "             shit : +243.21\n",
      "               go : +221.11\n",
      "             like : +218.65\n",
      "              are : +213.84\n",
      "            their : +201.80\n",
      "              his : +201.66\n",
      "              all : +174.49\n",
      "           people : +163.78\n",
      "              get : +163.49\n",
      "             they : +161.92\n",
      "             your : +150.60\n",
      "            idiot : +127.86\n",
      "            to be : +123.08\n",
      "\n",
      "Bottom 20 →\n",
      "              the : -1496.34\n",
      "               in : -1483.90\n",
      "               to : -1122.50\n",
      "               of : -633.55\n",
      "               it : -599.71\n",
      "              not : -580.75\n",
      "              for : -558.97\n",
      "             with : -460.40\n",
      "              and : -460.27\n",
      "            there : -374.39\n",
      "               at : -325.91\n",
      "             just : -302.61\n",
      "            about : -297.82\n",
      "               on : -267.13\n",
      "              but : -262.53\n",
      "               we : -249.35\n",
      "             have : -248.98\n",
      "               as : -243.79\n",
      "               if : -241.27\n",
      "            could : -222.29\n",
      "\n",
      "=== Reddit-based importance for 'identity_hate' ===\n",
      "Top 20 →\n",
      "              you : +568.41\n",
      "             they : +391.92\n",
      "               is : +344.40\n",
      "               we : +334.12\n",
      "               so : +297.04\n",
      "            their : +196.97\n",
      "              out : +190.45\n",
      "           in the : +175.69\n",
      "          country : +170.08\n",
      "             hate : +137.35\n",
      "              are : +134.47\n",
      "               go : +116.24\n",
      "            being : +113.50\n",
      "             shit : +113.26\n",
      "          fucking : +108.48\n",
      "           always : +102.98\n",
      "             fuck : +95.10\n",
      "         from the : +93.72\n",
      "           stupid : +91.97\n",
      "          of this : +91.29\n",
      "\n",
      "Bottom 20 →\n",
      "              the : -1857.23\n",
      "               it : -1636.09\n",
      "               of : -1531.66\n",
      "               in : -1008.79\n",
      "              for : -999.78\n",
      "              not : -808.77\n",
      "             this : -674.04\n",
      "               to : -630.16\n",
      "             that : -566.63\n",
      "              was : -491.05\n",
      "               on : -395.91\n",
      "            there : -337.57\n",
      "               at : -310.58\n",
      "               as : -258.67\n",
      "              now : -237.66\n",
      "              see : -222.55\n",
      "             been : -222.51\n",
      "               no : -217.05\n",
      "              any : -215.69\n",
      "             just : -210.46\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "vect = model.named_steps['vect']\n",
    "ovr  = model.named_steps['clf']\n",
    "feature_names = vect.get_feature_names_out()\n",
    "\n",
    "# transform all Reddit comments\n",
    "X_reddit = vect.transform(df_all['body'])  \n",
    "\n",
    "# compute and print feature importances per label\n",
    "for idx, label in enumerate(label_cols):\n",
    "    lr      = ovr.estimators_[idx]\n",
    "    w       = lr.coef_[0]\n",
    "    contrib = X_reddit.multiply(w).sum(axis=0).A1  # dense array\n",
    "\n",
    "    top_idx = np.argsort(contrib)[-20:][::-1]\n",
    "    bot_idx = np.argsort(contrib)[:20]\n",
    "\n",
    "    print(f\"\\n=== Reddit-based importance for '{label}' ===\")\n",
    "    print(\"Top 20 →\")\n",
    "    for j in top_idx:\n",
    "        print(f\"  {feature_names[j]:>15} : {contrib[j]:+.2f}\")\n",
    "    print(\"\\nBottom 20 →\")\n",
    "    for j in bot_idx:\n",
    "        print(f\"  {feature_names[j]:>15} : {contrib[j]:+.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine sample with its predictions\n",
    "results = pd.concat([\n",
    "    df_all,\n",
    "    pd.DataFrame(preds, columns=label_cols)\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a results DataFrame\n",
    "results_df = pd.DataFrame(preds, columns=label_cols)\n",
    "df_out     = pd.concat([df_all, results_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.head(10))       # first 10 of your 100-comment sample\n",
    "print(\"\\nLabel counts in this sample:\\n\", results[label_cols].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"reddit_sample_with_predictions.csv\")\n",
    "results.to_csv(output_path, index=False)\n",
    "print(f\"Saved sample with predictions to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f0726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect some examples\n",
    "print(df_out.head())\n",
    "\n",
    "# Summary stats: how many comments flagged toxic/insult/etc.\n",
    "print(df_out[label_cols].sum())\n",
    "\n",
    "# Save to CSV\n",
    "df_out.to_csv(\"reddit_comments_with_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my-project)",
   "language": "python",
   "name": "exam_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
